{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb5005a",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install selenium pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d07d1f8",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0decfb17",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e5d2eec4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2: Scraping article details (one row per author)...\n",
            "Reading from: /Users/keerthisagi/Documents/Journals/MIS_Quarterly/MISQ_Issues.csv\n",
            "Writing to: /Users/keerthisagi/Documents/Journals/MIS_Quarterly/MISQ_article_data.csv\n",
            "\n",
            "Total articles: 1273\n",
            "Processing range: 0 to 5\n",
            "\n",
            "[1] Bot detection - waiting 30s...\n",
            "[1/5] Information Systems Innovation for Environmental S... (1 author(s))\n",
            "[2/5] Information Systems and Environmentally Sustainabl... (3 author(s))\n",
            "[3/5] An Empirical Analysis of the Impact of Information... (3 author(s))\n",
            "[4/5] Chasing the Hottest IT: Effects of Information Tec... (1 author(s))\n",
            "[5/5] Toward Agile: An Integrated Analysis of Quantitati... (2 author(s))\n",
            "\n",
            "Step 2 complete. Data saved to /Users/keerthisagi/Documents/Journals/MIS_Quarterly/MISQ_article_data.csv\n"
          ]
        }
      ],
      "source": [
        "# ========== STEP 2: Scrape detailed data for each article ==========\n",
        "# Reads MISQ_Issues.csv, visits each URL, extracts title/abstract/keywords/authors.\n",
        "# Writes MISQ_article_data.csv with ONE ROW PER AUTHOR (same article info, author name changes).\n",
        "# Run Step 1 first to create MISQ_Issues.csv.\n",
        "\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "START_INDEX = 0\n",
        "END_INDEX = 5  # Process in batches; use len(journals_data) for all\n",
        "\n",
        "OUT_DIR = os.getcwd()\n",
        "CSV_PATH = os.path.join(OUT_DIR, 'MISQ_Issues.csv')\n",
        "OUT_FILE = os.path.join(OUT_DIR, 'MISQ_article_data.csv')\n",
        "\n",
        "print(\"Step 2: Scraping article details (one row per author)...\")\n",
        "print(f\"Reading from: {CSV_PATH}\")\n",
        "print(f\"Writing to: {OUT_FILE}\\n\")\n",
        "\n",
        "journals_data = pd.read_csv(CSV_PATH)\n",
        "n_total = len(journals_data)\n",
        "print(f\"Total articles: {n_total}\")\n",
        "print(f\"Processing range: {START_INDEX} to {min(END_INDEX, n_total)}\\n\")\n",
        "\n",
        "if not os.path.exists(OUT_FILE) or os.path.getsize(OUT_FILE) == 0:\n",
        "    with open(OUT_FILE, 'a', newline='', encoding='utf-8') as f:\n",
        "        csv.writer(f).writerow(['URL','Journal_Title','Article_Title','Volume_Issue','Month_Year','Abstract','Keywords','Author_name','Author_email','Author_Address'])\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
        "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
        "chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
        "\n",
        "def is_bot_page(driver):\n",
        "    title = (driver.title or '').lower()\n",
        "    url = (driver.current_url or '').lower()\n",
        "    return 'validate' in title or 'bot' in title or 'captcha' in title or 'crawlprevention' in url\n",
        "\n",
        "def get_authors(driver):\n",
        "    \"\"\"One row per author. Splits combined text (e.g. 'A1\\\\nA2\\\\nA3') into individual names.\"\"\"\n",
        "    authdata = []\n",
        "    seen = set()\n",
        "    skip = {'n/a', 'author', 'authors', 'author & article information', 'author information', 'article information'}\n",
        "    try:\n",
        "        selectors = ['.author-name', '.author .name', '[itemprop=\"author\"]', '.byline .author', '.contributor-name',\n",
        "                     '.author, .contributor, [class*=\"author\"], .byline span']\n",
        "        all_parts = []\n",
        "        for sel in selectors:\n",
        "            try:\n",
        "                for el in driver.find_elements(By.CSS_SELECTOR, sel):\n",
        "                    text = (el.text or '').strip()\n",
        "                    if not text or len(text) < 3:\n",
        "                        continue\n",
        "                    for part in re.split(r'[\\n;]+', text):\n",
        "                        part = part.strip()\n",
        "                        if part and 3 <= len(part) <= 80:\n",
        "                            all_parts.append(part)\n",
        "                if all_parts:\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "        for name in all_parts:\n",
        "            name = ' '.join(name.split()).replace(';', '').strip()\n",
        "            if not name or len(name) < 3 or len(name) > 80 or name.lower() in skip or name.startswith('Author') or name.startswith('Article'):\n",
        "                continue\n",
        "            key = name.lower()\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                authdata.append([name, \"N/A\", \"N/A\"])\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting authors: {e}\")\n",
        "    return authdata if authdata else [[\"N/A\", \"N/A\", \"N/A\"]]\n",
        "\n",
        "try:\n",
        "    for index, row in journals_data.iloc[START_INDEX:END_INDEX].iterrows():\n",
        "        url = str(row.get('URL', '')).strip()\n",
        "        article_date = row.get('Vol Issue Year', None)\n",
        "        article_vol = row.get('Volume Issue', 'N/A')\n",
        "        if not url or not url.startswith('http'):\n",
        "            continue\n",
        "\n",
        "        title, abstract, keyword_list = \"N/A\", None, []\n",
        "\n",
        "        try:\n",
        "            time.sleep(random.uniform(3, 7))\n",
        "            driver.get(url)\n",
        "            driver.implicitly_wait(10)\n",
        "            time.sleep(random.uniform(1, 3))\n",
        "\n",
        "            if is_bot_page(driver):\n",
        "                print(f\"[{index-START_INDEX+1}] Bot detection - waiting 30s...\")\n",
        "                time.sleep(30)\n",
        "                driver.get(url)\n",
        "                time.sleep(3)\n",
        "                if is_bot_page(driver):\n",
        "                    print(\"  Still blocked. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "            for sel in ['h1', '.article-title', '.title', 'article h1']:\n",
        "                try:\n",
        "                    title = driver.find_element(By.CSS_SELECTOR, sel).text.strip()\n",
        "                    if title and len(title) > 3:\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            for sel in ['.abstract', '#abstract', '.article-abstract', 'section.abstract', '[class*=\"abstract\"]']:\n",
        "                try:\n",
        "                    abstract = driver.find_element(By.CSS_SELECTOR, sel).text.strip()\n",
        "                    if abstract and len(abstract) > 20:\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            try:\n",
        "                keyword_list = [k.text.strip() for k in driver.find_elements(By.CSS_SELECTOR, '.keyword, .keywords span, .tag, [class*=\"keyword\"] span') if k.text.strip()]\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            auth_data = get_authors(driver)\n",
        "            final_data = [url, \"MIS Quarterly\", title, article_vol, article_date, abstract, keyword_list]\n",
        "\n",
        "            with open(OUT_FILE, 'a', newline='', encoding='utf-8') as f:\n",
        "                writer = csv.writer(f)\n",
        "                for auth in auth_data:\n",
        "                    writer.writerow(final_data + auth)\n",
        "                f.flush()\n",
        "\n",
        "            print(f\"[{index-START_INDEX+1}/{min(END_INDEX, n_total)-START_INDEX}] {title[:50]}... ({len(auth_data)} author(s))\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[{index-START_INDEX+1}] Error: {e}\")\n",
        "            with open(OUT_FILE, 'a', newline='', encoding='utf-8') as f:\n",
        "                csv.writer(f).writerow([url, \"MIS Quarterly\", \"N/A\", article_vol, article_date, None, [], \"N/A\", \"N/A\", \"N/A\"])\n",
        "                f.flush()\n",
        "\n",
        "finally:\n",
        "    driver.quit()\n",
        "    print(f\"\\nStep 2 complete. Data saved to {OUT_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "98440492",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠ Bot page hit. Solve in browser, then press ENTER. URL: https://misq.umn.edu/misq/article/34/1/1/488/Information-Systems-Innovation-for-Environmental\n",
            "✓ N/A... (1 author(s))\n",
            "DONE: MISQ_article_data.csv\n"
          ]
        },
        {
          "ename": "NoSuchWindowException",
          "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=145.0.7632.109)\nStacktrace:\n0   chromedriver                        0x0000000102623d84 cxxbridge1$str$ptr + 3127864\n1   chromedriver                        0x000000010261c174 cxxbridge1$str$ptr + 3096104\n2   chromedriver                        0x00000001020f99f4 _RNvCsdExgN8vFLbb_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 75356\n3   chromedriver                        0x00000001020d28c4 chromedriver + 157892\n4   chromedriver                        0x000000010216a994 _RNvCsdExgN8vFLbb_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 538108\n5   chromedriver                        0x00000001021806b4 _RNvCsdExgN8vFLbb_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 627484\n6   chromedriver                        0x00000001021362bc _RNvCsdExgN8vFLbb_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 323364\n7   chromedriver                        0x00000001025e28a8 cxxbridge1$str$ptr + 2860380\n8   chromedriver                        0x00000001025e5fe8 cxxbridge1$str$ptr + 2874524\n9   chromedriver                        0x00000001025c7cc4 cxxbridge1$str$ptr + 2750840\n10  chromedriver                        0x00000001025e686c cxxbridge1$str$ptr + 2876704\n11  chromedriver                        0x00000001025b82cc cxxbridge1$str$ptr + 2686848\n12  chromedriver                        0x000000010260af68 cxxbridge1$str$ptr + 3025948\n13  chromedriver                        0x000000010260b0e4 cxxbridge1$str$ptr + 3026328\n14  chromedriver                        0x000000010261bdcc cxxbridge1$str$ptr + 3095168\n15  libsystem_pthread.dylib             0x0000000196503bc8 _pthread_start + 136\n16  libsystem_pthread.dylib             0x00000001964feb80 thread_start + 8\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 128\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Smaller jitter (faster than 3–7 seconds)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.8\u001b[39m))\n\u001b[0;32m--> 128\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Bot handling (manual)\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bot_page(driver):\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/selenium/webdriver/remote/webdriver.py:452\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Navigate the browser to the specified URL.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    The method does not return until the page is fully loaded (i.e. the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m        `driver.get(\"https://example.com\")`\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/selenium/webdriver/remote/webdriver.py:432\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    429\u001b[0m response \u001b[38;5;241m=\u001b[39m cast(RemoteConnection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor)\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[1;32m    433\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/selenium/webdriver/remote/errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
            "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=145.0.7632.109)\nStacktrace:\n0   chromedriver                        0x0000000102623d84 cxxbridge1$str$ptr + 3127864\n1   chromedriver                        0x000000010261c174 cxxbridge1$str$ptr + 3096104\n2   chromedriver                        0x00000001020f99f4 _RNvCsdExgN8vFLbb_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 75356\n3   chromedriver                        0x00000001020d28c4 chromedriver + 157892\n4   chromedriver                        0x000000010216a994 _RNvCsdExgN8vFLbb_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 538108\n5   chromedriver                        0x00000001021806b4 _RNvCsdExgN8vFLbb_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 627484\n6   chromedriver                        0x00000001021362bc _RNvCsdExgN8vFLbb_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 323364\n7   chromedriver                        0x00000001025e28a8 cxxbridge1$str$ptr + 2860380\n8   chromedriver                        0x00000001025e5fe8 cxxbridge1$str$ptr + 2874524\n9   chromedriver                        0x00000001025c7cc4 cxxbridge1$str$ptr + 2750840\n10  chromedriver                        0x00000001025e686c cxxbridge1$str$ptr + 2876704\n11  chromedriver                        0x00000001025b82cc cxxbridge1$str$ptr + 2686848\n12  chromedriver                        0x000000010260af68 cxxbridge1$str$ptr + 3025948\n13  chromedriver                        0x000000010260b0e4 cxxbridge1$str$ptr + 3026328\n14  chromedriver                        0x000000010261bdcc cxxbridge1$str$ptr + 3095168\n15  libsystem_pthread.dylib             0x0000000196503bc8 _pthread_start + 136\n16  libsystem_pthread.dylib             0x00000001964feb80 thread_start + 8\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "START_INDEX = 0\n",
        "END_INDEX = 200  # set to len(journals_data) for all\n",
        "\n",
        "journals_data = pd.read_csv('MISQ_Issues.csv')\n",
        "OUT_FILE = 'MISQ_article_data.csv'\n",
        "\n",
        "WAIT_SEC = 15\n",
        "\n",
        "def is_bot_page(driver):\n",
        "    title = (driver.title or '').lower()\n",
        "    url = (driver.current_url or '').lower()\n",
        "    src = (driver.page_source or '').lower()\n",
        "    signals = ['validate', 'bot', 'captcha', 'crawlprevention', 'verification', 'are you human', 'cloudflare']\n",
        "    return any(s in title for s in signals) or any(s in url for s in signals) or any(s in src for s in signals)\n",
        "\n",
        "def getAuthorsData(driver):\n",
        "    authdata = []\n",
        "    seen = set()\n",
        "    skip = {\n",
        "        'n/a', 'author', 'authors', 'author & article information',\n",
        "        'author information', 'article information'\n",
        "    }\n",
        "\n",
        "    selectors = [\n",
        "        '.author-name',\n",
        "        '.author .name',\n",
        "        '[itemprop=\"author\"]',\n",
        "        '.byline .author',\n",
        "        '.contributor-name',\n",
        "        '.author, .contributor, [class*=\"author\"], .byline span'\n",
        "    ]\n",
        "\n",
        "    all_parts = []\n",
        "    for sel in selectors:\n",
        "        try:\n",
        "            els = driver.find_elements(By.CSS_SELECTOR, sel)\n",
        "            for el in els:\n",
        "                text = (el.text or '').strip()\n",
        "                if not text or len(text) < 3:\n",
        "                    continue\n",
        "                for part in re.split(r'[\\n;]+', text):\n",
        "                    part = part.strip()\n",
        "                    if part and 3 <= len(part) <= 80:\n",
        "                        all_parts.append(part)\n",
        "            if all_parts:\n",
        "                break\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    for name in all_parts:\n",
        "        name = ' '.join(name.split()).replace(';', '').strip()\n",
        "        if not name or len(name) < 3 or len(name) > 80:\n",
        "            continue\n",
        "        low = name.lower()\n",
        "        if low in skip:\n",
        "            continue\n",
        "        if name.startswith('Author') or name.startswith('Article'):\n",
        "            continue\n",
        "        if low not in seen:\n",
        "            seen.add(low)\n",
        "            authdata.append([name, \"N/A\", \"N/A\"])\n",
        "\n",
        "    return authdata if authdata else [[\"N/A\", \"N/A\", \"N/A\"]]\n",
        "\n",
        "# Write header once\n",
        "if not os.path.exists(OUT_FILE) or os.path.getsize(OUT_FILE) == 0:\n",
        "    with open(OUT_FILE, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\n",
        "            'URL','Journal_Title','Article_Title','Volume_Issue','Month_Year',\n",
        "            'Abstract','Keywords','Author_name','Author_email','Author_Address'\n",
        "        ])\n",
        "\n",
        "# Chrome options: faster loads (block images/fonts/styles)\n",
        "opts = Options()\n",
        "prefs = {\n",
        "    \"profile.managed_default_content_settings.images\": 2,\n",
        "    \"profile.managed_default_content_settings.stylesheets\": 2,\n",
        "    \"profile.managed_default_content_settings.fonts\": 2,\n",
        "}\n",
        "opts.add_experimental_option(\"prefs\", prefs)\n",
        "\n",
        "driver = webdriver.Chrome(options=opts)\n",
        "wait = WebDriverWait(driver, WAIT_SEC)\n",
        "\n",
        "# Optional: batch writes\n",
        "buffer_rows = []\n",
        "BUFFER_SIZE = 50\n",
        "\n",
        "def flush_buffer():\n",
        "    global buffer_rows\n",
        "    if not buffer_rows:\n",
        "        return\n",
        "    with open(OUT_FILE, mode='a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerows(buffer_rows)\n",
        "        file.flush()\n",
        "    buffer_rows = []\n",
        "\n",
        "try:\n",
        "    for idx, row in journals_data.iloc[START_INDEX:END_INDEX].iterrows():\n",
        "        url = str(row.get('URL', '')).strip()\n",
        "        article_date = row.get('Vol Issue Year', None)\n",
        "        article_vol = row.get('Volume Issue', 'N/A')\n",
        "\n",
        "        if not url.startswith('http'):\n",
        "            continue\n",
        "\n",
        "        title = \"N/A\"\n",
        "        abstract = None\n",
        "        keyword_list = []\n",
        "\n",
        "        # Smaller jitter (faster than 3–7 seconds)\n",
        "        time.sleep(random.uniform(0.8, 1.8))\n",
        "\n",
        "        driver.get(url)\n",
        "\n",
        "        # Bot handling (manual)\n",
        "        if is_bot_page(driver):\n",
        "            print(f\"⚠ Bot page hit. Solve in browser, then press ENTER. URL: {url}\")\n",
        "            input()\n",
        "            driver.get(url)\n",
        "\n",
        "        # Wait for page to load enough (title)\n",
        "        try:\n",
        "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"body\")))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Title\n",
        "        for sel in ['h1', '.article-title', '.title', 'article h1']:\n",
        "            try:\n",
        "                title = driver.find_element(By.CSS_SELECTOR, sel).text.strip()\n",
        "                if title and len(title) > 3:\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Abstract\n",
        "        for sel in ['.abstract', '#abstract', '.article-abstract', 'section.abstract', '[class*=\"abstract\"]']:\n",
        "            try:\n",
        "                abstract = driver.find_element(By.CSS_SELECTOR, sel).text.strip()\n",
        "                if abstract and len(abstract) > 20:\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Keywords\n",
        "        try:\n",
        "            keyword_list = [\n",
        "                k.text.strip()\n",
        "                for k in driver.find_elements(By.CSS_SELECTOR, '.keyword, .keywords span, .tag, [class*=\"keyword\"] span')\n",
        "                if k.text.strip()\n",
        "            ]\n",
        "        except:\n",
        "            keyword_list = []\n",
        "\n",
        "        final_data = [url, \"MIS Quarterly\", title, article_vol, article_date, abstract, keyword_list]\n",
        "\n",
        "        auth_data = getAuthorsData(driver)\n",
        "        for arow in auth_data:\n",
        "            buffer_rows.append(final_data + arow)\n",
        "\n",
        "        if len(buffer_rows) >= BUFFER_SIZE:\n",
        "            flush_buffer()\n",
        "\n",
        "        print(f\"✓ {title[:60]}... ({len(auth_data)} author(s))\")\n",
        "\n",
        "finally:\n",
        "    flush_buffer()\n",
        "    driver.quit()\n",
        "    print(\"DONE:\", OUT_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78bf8a5",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
