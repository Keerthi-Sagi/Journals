{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd5bd172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: information_and_organization_MASTER_READY.csv\n",
      "Rows: 778\n",
      "Unique URLs: 350\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "INPUT_FILE = \"information_and_organization_journal_articles.csv\"\n",
    "OUTPUT_FILE = \"information_and_organization_MASTER_READY.csv\"\n",
    "\n",
    "MASTER_COLUMNS = [\n",
    "    \"URL\",\n",
    "    \"Journal_Title\",\n",
    "    \"Standardized_Title\",\n",
    "    \"month_year\",\n",
    "    \"Abstract\",\n",
    "    \"Keywords\",\n",
    "    \"Author_Name\",\n",
    "    \"Standardized_Author\",\n",
    "    \"Author_University\",\n",
    "    \"Standardized_University\",\n",
    "    \"Author_State\",\n",
    "    \"Author_Country\",\n",
    "]\n",
    "\n",
    "NA_LIKE_VALUES = {\n",
    "    \"\", \" \", \"NA\", \"N/A\", \"na\", \"n/a\",\n",
    "    \"NULL\", \"null\", \"None\", \"none\", \"-\"\n",
    "}\n",
    "\n",
    "def generate_standardized_title(title):\n",
    "    if pd.isna(title):\n",
    "        return np.nan\n",
    "    text = str(title).strip().lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def clean_author_level_to_master(input_csv: str, output_csv: str):\n",
    "    data = pd.read_csv(input_csv, header=None)\n",
    "\n",
    "    if data.shape[1] != 10:\n",
    "        raise ValueError(\n",
    "            f\"{input_csv} has {data.shape[1]} columns; expected 10 for the journal_articles file.\"\n",
    "        )\n",
    "\n",
    "    data.columns = [\n",
    "        \"URL\",\n",
    "        \"Journal_Title\",\n",
    "        \"Article_Title\",\n",
    "        \"Volume_Issue\",\n",
    "        \"month_year\",\n",
    "        \"Abstract\",\n",
    "        \"Keywords\",\n",
    "        \"Author_name\",\n",
    "        \"Author_email\",\n",
    "        \"Author_Address\",\n",
    "    ]\n",
    "\n",
    "    data = data.replace(list(NA_LIKE_VALUES), np.nan)\n",
    "\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype(\"string\").str.strip()\n",
    "\n",
    "    data = data.dropna(subset=[\"URL\", \"Article_Title\"])\n",
    "\n",
    "    data = data.drop_duplicates(\n",
    "        subset=[\"URL\", \"Author_name\", \"Author_email\", \"Author_Address\"],\n",
    "        keep=\"first\"\n",
    "    )\n",
    "\n",
    "    cleaned = pd.DataFrame({\n",
    "        \"URL\": data[\"URL\"],\n",
    "        \"Journal_Title\": data[\"Journal_Title\"],\n",
    "        \"Standardized_Title\": data[\"Article_Title\"].apply(generate_standardized_title),\n",
    "        \"month_year\": data[\"month_year\"],\n",
    "        \"Abstract\": data[\"Abstract\"],\n",
    "        \"Keywords\": data[\"Keywords\"],\n",
    "        \"Author_Name\": data[\"Author_name\"],\n",
    "        \"Standardized_Author\": np.nan,\n",
    "        \"Author_University\": np.nan,\n",
    "        \"Standardized_University\": np.nan,\n",
    "        \"Author_State\": np.nan,\n",
    "        \"Author_Country\": np.nan,\n",
    "    })[MASTER_COLUMNS]\n",
    "\n",
    "    cleaned.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved: {output_csv}\")\n",
    "    print(f\"Rows: {len(cleaned)}\")\n",
    "    print(f\"Unique URLs: {cleaned['URL'].nunique()}\")\n",
    "\n",
    "clean_author_level_to_master(INPUT_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d09166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: information_and_organization_ENRICHED.csv\n",
      "Rows: 778\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "INPUT_FILE = \"information_and_organization_MASTER_READY.csv\"\n",
    "OUTPUT_FILE = \"information_and_organization_ENRICHED.csv\"\n",
    "\n",
    "def extract_author_affiliation(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\n",
    "            \"Author_University\": None,\n",
    "            \"Author_State\": None,\n",
    "            \"Author_Country\": None\n",
    "        }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Extract the following details from the author affiliation text.\n",
    "\n",
    "Return ONLY JSON with these exact keys:\n",
    "Author_University, Author_State, Author_Country\n",
    "\n",
    "Use official English names.\n",
    "Standardize country names (US/USA -> United States).\n",
    "Standardize state names (CA -> California).\n",
    "If unknown, return null.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "JSON:\n",
    "{{\n",
    "  \"Author_University\": \"Wichita State University\",\n",
    "  \"Author_State\": \"Kansas\",\n",
    "  \"Author_Country\": \"United States\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You extract structured academic affiliation data.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        data = json.loads(content)\n",
    "\n",
    "        return {\n",
    "            \"Author_University\": data.get(\"Author_University\"),\n",
    "            \"Author_State\": data.get(\"Author_State\"),\n",
    "            \"Author_Country\": data.get(\"Author_Country\")\n",
    "        }\n",
    "\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"Author_University\": None,\n",
    "            \"Author_State\": None,\n",
    "            \"Author_Country\": None\n",
    "        }\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "universities = []\n",
    "states = []\n",
    "countries = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    combined_text = f\"{row.get('Author_Name','')} {row.get('Author_Address','')}\"\n",
    "    result = extract_author_affiliation(combined_text)\n",
    "\n",
    "    universities.append(result[\"Author_University\"])\n",
    "    states.append(result[\"Author_State\"])\n",
    "    countries.append(result[\"Author_Country\"])\n",
    "\n",
    "    time.sleep(0.4)\n",
    "\n",
    "df[\"Author_University\"] = universities\n",
    "df[\"Author_State\"] = states\n",
    "df[\"Author_Country\"] = countries\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"Saved:\", OUTPUT_FILE)\n",
    "print(\"Rows:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c8699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: information_and_organization_FOR_STANDARDIZATION.csv\n",
      "Unique universities: 0\n",
      "Unique authors: 576\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "INPUT_FILE = \"information_and_organization_ENRICHED.csv\"\n",
    "OUTPUT_FILE = \"information_and_organization_FOR_STANDARDIZATION.csv\"\n",
    "\n",
    "def normalize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "df[\"University_norm\"] = df[\"Author_University\"].apply(normalize_text)\n",
    "df[\"Author_norm\"] = df[\"Author_Name\"].apply(normalize_text)\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"Saved:\", OUTPUT_FILE)\n",
    "print(\"Unique universities:\", df[\"University_norm\"].nunique())\n",
    "print(\"Unique authors:\", df[\"Author_norm\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f992a0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['University_norm', 'Author_University'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation_and_organization_journal_articles.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m univ_map \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m     df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniversity_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthor_University\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniversity_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m univ_map[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStandardized_University\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m univ_map[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthor_University\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m univ_map\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniversity_mapping.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['University_norm', 'Author_University'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"information_and_organization_journal_articles.csv\")\n",
    "\n",
    "univ_map = (\n",
    "    df[[\"University_norm\", \"Author_University\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"University_norm\")\n",
    ")\n",
    "\n",
    "univ_map[\"Standardized_University\"] = univ_map[\"Author_University\"]\n",
    "\n",
    "univ_map.to_csv(\"university_mapping.csv\", index=False)\n",
    "\n",
    "print(\"Saved: university_mapping.csv\")\n",
    "print(\"Rows:\", len(univ_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134d5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
